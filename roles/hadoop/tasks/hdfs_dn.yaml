---
- name: Create directory for pid
  file:
    path: '{{ hadoop_hdfs_pid_dir }}'
    state: directory
    group: '{{ hadoop_group }}'
    owner: '{{ hdfs_user }}'

- name: Template hadoop hdfs tmpfiles.d
  template:
    src: tmpfiles-hadoop-hdfs.conf.j2
    dest: /etc/tmpfiles.d/hadoop-hdfs.conf

- name: Create HDFS directory
  file:
    path: "{{ hdfs_site['dfs.datanode.data.dir'] }}"
    state: directory
    group: '{{ hadoop_group }}'
    owner: '{{ hdfs_user }}'

- name: Create log directory
  file:
    path: '{{ hadoop_hdfs_log_dir }}'
    state: directory
    group: '{{ hadoop_group }}'
    owner: '{{ hdfs_user }}'

- name: Create configuration directory
  file:
    path: '{{ hadoop_dn_conf_dir }}'
    state: directory
    group: '{{ hadoop_group }}'
    owner: '{{ hdfs_user }}'

- name: Backup configuration
  copy:
    src: '{{ hadoop_dn_conf_dir }}/'
    dest: '{{ hadoop_dn_conf_dir }}.{{ ansible_date_time.epoch }}'
    group: '{{ hadoop_group }}'
    owner: '{{ hdfs_user }}'
    remote_src: yes
  tags:
    - backup

- name: Template hadoop-env.sh
  template:
    src: hadoop-env.sh.j2
    dest: '{{ hadoop_dn_conf_dir }}/hadoop-env.sh'
  vars:
    hadoop_log_dir: "{{ hadoop_hdfs_log_dir }}"
    hadoop_pid_dir: "{{ hadoop_hdfs_pid_dir }}"

- name: Template log4j.properties
  template:
    src: log4j.properties.j2
    dest: '{{ hadoop_dn_conf_dir }}/log4j.properties'
  vars:
    hadoop_log_dir: "{{ hadoop_hdfs_log_dir }}"

- name: Template HDFS Datanode service file
  template:
    src: hadoop-hdfs-datanode.service.j2
    dest: /usr/lib/systemd/system/hadoop-hdfs-datanode.service

- name: Render core-site.xml
  template:
    src: core-site.xml.j2
    dest: '{{ hadoop_dn_conf_dir }}/core-site.xml'

- name: Render hdfs-site.xml
  template:
    src: hdfs-site.xml.j2
    dest: '{{ hadoop_dn_conf_dir }}/hdfs-site.xml'

- name: Render ssl-server.xml
  template:
    src: ssl-server.xml.j2
    dest: '{{ hadoop_dn_conf_dir }}/ssl-server.xml'

- name: Generate principals and keytabs
  shell: |
    kadmin -r {{ realm }} -p {{ kadmin_principal }} -w {{ kadmin_password }} -q "addprinc -randkey dn/{{ ansible_fqdn }}"
    kadmin -r {{ realm }} -p {{ kadmin_principal }} -w {{ kadmin_password }} -q "xst -k dn.service.keytab dn/{{ ansible_fqdn }}@{{ realm }}"
    chown {{ hdfs_user }}:{{ hadoop_group }} dn.service.keytab
  args:
    chdir: /etc/security/keytabs
    creates: /etc/security/keytabs/dn.service.keytab

- name: Convert cert and key to pk12
  shell: |
    openssl pkcs12 \
      -export \
      -in /etc/ssl/certs/{{ ansible_fqdn }}.pem \
      -inkey /etc/ssl/certs/{{ ansible_fqdn }}.key \
      -out /etc/ssl/certs/{{ ansible_fqdn }}.p12 \
      -name {{ ansible_fqdn }} \
      -CAfile /etc/ssl/certs/root.pem \
      -caname root_ca \
      -password pass:{{ hadoop_keystore_password }}
  args:
    creates: '/etc/ssl/certs/{{ ansible_fqdn }}.p12'

- name: Create keystore and add Certificate Authority into it
  shell: |
    keytool \
      -importkeystore \
      -deststorepass {{ hadoop_keystore_password }} \
      -destkeypass {{ hadoop_keystore_password }} \
      -destkeystore {{ hadoop_keystore_location }} \
      -srckeystore /etc/ssl/certs/{{ ansible_fqdn }}.p12 \
      -srcstoretype PKCS12 \
      -srcstorepass {{ hadoop_keystore_password }} \
      -alias {{ ansible_fqdn }}

    keytool \
      -keystore {{ hadoop_keystore_location }} \
      -alias root_ca \
      -import \
      -file /etc/ssl/certs/root.pem \
      -storepass {{ hadoop_keystore_password }} \
      -noprompt
  args:
    creates: '{{ hadoop_keystore_location }}'

- name: Create truststore
  shell: |
    keytool \
      -keystore {{ hadoop_truststore_location }} \
      -deststorepass {{ hadoop_truststore_password }} \
      -alias root_ca \
      -import \
      -file /etc/ssl/certs/root.pem \
      -noprompt
  args:
    creates: '{{ hadoop_truststore_location }}'
