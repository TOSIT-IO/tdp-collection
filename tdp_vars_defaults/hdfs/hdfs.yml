# Copyright 2022 TOSIT.IO
# SPDX-License-Identifier: Apache-2.0

---
hdfs_user: hdfs

hadoop_hdfs_dir: /var/lib/hdfs
hadoop_hdfs_pid_dir: /run/hadoop/hdfs
hadoop_log_dir: "{{ hdfs_log_dir }}"

# hdfs-site.xml - common
# TODO: make a hdfs_site per service: nn, jn, dn
hdfs_site:
  dfs.nameservices: "{{ cluster_name }}"
  "dfs.ha.namenodes.{{ cluster_name }}": nn1,nn2
  dfs.ha.fencing.methods: shell(/bin/true)
  dfs.ha.automatic-failover.enabled: "true"
  dfs.ha.zkfc.port: "{{ hdfs_zkfc_rpc_port }}"
  dfs.http.policy: HTTPS_ONLY
  dfs.data.transfer.protection: authentication
  dfs.web.authentication.kerberos.keytab: /etc/security/keytabs/spnego.service.keytab
  dfs.web.authentication.kerberos.principal: "HTTP/_HOST@{{ realm }}"
  "dfs.namenode.rpc-address.{{ cluster_name }}.nn1": "{{ groups['hdfs_nn'][0] | tosit.tdp.access_fqdn(hostvars) }}:{{ hdfs_nn_rpc_port }}"
  "dfs.namenode.rpc-address.{{ cluster_name }}.nn2": "{{ groups['hdfs_nn'][1] | tosit.tdp.access_fqdn(hostvars) }}:{{ hdfs_nn_rpc_port }}"
  "dfs.namenode.http-address.{{ cluster_name }}.nn1": "{{ groups['hdfs_nn'][0] | tosit.tdp.access_fqdn(hostvars) }}:{{ hdfs_nn_http_port }}"
  "dfs.namenode.http-address.{{ cluster_name }}.nn2": "{{ groups['hdfs_nn'][1] | tosit.tdp.access_fqdn(hostvars) }}:{{ hdfs_nn_http_port }}"
  "dfs.namenode.https-address.{{ cluster_name }}.nn1": "{{ groups['hdfs_nn'][0] | tosit.tdp.access_fqdn(hostvars) }}:{{ hdfs_nn_https_port }}"
  "dfs.namenode.https-address.{{ cluster_name }}.nn2": "{{ groups['hdfs_nn'][1] | tosit.tdp.access_fqdn(hostvars) }}:{{ hdfs_nn_https_port }}"
  dfs.namenode.name.dir: "{{ hdfs_namenode_data_dirs }}"
  dfs.namenode.shared.edits.dir: |-
    qjournal://{{ groups['hdfs_jn'] |
       map('tosit.tdp.access_fqdn', hostvars) |
       map('regex_replace', '^(.*)$', '\1:' + hdfs_jn_rpc_port | string) |
       list |
       join(';')
    }}/{{ cluster_name }}

  dfs.namenode.kerberos.principal: "nn/_HOST@{{ realm }}"
  dfs.namenode.keytab.file: /etc/security/keytabs/nn.service.keytab
  dfs.namenode.kerberos.internal.spnego.principal: "HTTP/_HOST@{{ realm }}"
  dfs.namenode.num.checkpoints.retained: 3
  dfs.namenode.name.dir.restore: "true"
  "dfs.client.failover.proxy.provider.{{ cluster_name }}": org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider
  dfs.journalnode.edits.dir: "{{ hdfs_journalnode_data_dirs }}"
  dfs.journalnode.rpc-address: 0.0.0.0:{{ hdfs_jn_rpc_port }}
  dfs.journalnode.https-address: 0.0.0.0:{{ hdfs_jn_https_port }}
  dfs.journalnode.kerberos.principal: jn/_HOST@{{ realm }}
  dfs.journalnode.keytab.file: /etc/security/keytabs/jn.service.keytab
  dfs.journalnode.kerberos.internal.spnego.principal: "HTTP/_HOST@{{ realm }}"
  dfs.block.access.token.enable: "true"
  dfs.datanode.address: "0.0.0.0:{{ hdfs_dn_data_port }}"
  dfs.datanode.https.address: "0.0.0.0:{{ hdfs_dn_https_port }}"
  dfs.datanode.ipc.address: "0.0.0.0:{{ hdfs_dn_ipc_port }}"
  dfs.datanode.data.dir: "{{ hdfs_datanode_data_dirs }}"
  dfs.datanode.kerberos.principal: dn/_HOST@{{ realm }}
  dfs.datanode.keytab.file: /etc/security/keytabs/dn.service.keytab
  dfs.encryption.key.provider.uri: "{% if 'ranger_kms' in groups and groups['ranger_kms'] %}{{ ranger_kms_url }}{% else %}{% endif %}"

namenode_kerberos_principal: "nn/{{ ansible_fqdn }}@{{ realm }}"

# Ranger HDFS properties
ranger_hdfs_release: ranger-2.6.0-1.0-hdfs-plugin
ranger_hdfs_dist_file: "{{ ranger_hdfs_release }}.tar.gz"
ranger_hdfs_install_dir: "{{ hadoop_root_dir }}/ranger-hdfs-plugin"
ranger_hdfs_install_properties:
  POLICY_MGR_URL:  "{% if ranger_ha_address is defined %}{{ ranger_ha_address }}{% else %}https://{{ groups['ranger_admin'][0] | tosit.tdp.access_fqdn(hostvars) }}:{{ ranger_adm_https_port }}{% endif %}"
  REPOSITORY_NAME: hdfs-tdp
  XAAUDIT_SOLR_ENABLE: "{% if 'ranger_solr' in groups and groups['ranger_solr'] %}true{% else %}false{% endif %}"
  XAAUDIT_SOLR_URL: "{% if 'ranger_solr' in groups and groups['ranger_solr'] %}http://{{ groups['ranger_solr'][0] | tosit.tdp.access_fqdn(hostvars) }}:{{ ranger_solr_http_port }}/solr/ranger_audits{% else %}NONE{% endif %}"

# Service start on boot policies
hdfs_nn_start_on_boot: false
hdfs_dn_start_on_boot: false
hdfs_jn_start_on_boot: false
hdfs_zkfc_start_on_boot: false

# Service restart policies
hdfs_nn_restart: "no"
hdfs_dn_restart: "no"
hdfs_jn_restart: "no"
hdfs_zkfc_restart: "no"

# HDFS component & service check
hdfs_check_retries: 0
hdfs_check_delay: 5
hdfs_check_port_str: "Connected to"
hdfs_check_path_file: "/tmp/hdfs_service_check_{{ ansible_date_time.iso8601_basic }}.file"

# HDFS resources allocation
hdfs_namenode_heapsize: 2048m
hdfs_datanode_heapsize: 1024m
hdfs_journalnode_heapsize: 1024m
hdfs_zkfc_heapsize: 1024m

hdfs_namenode_data_dirs: "{{ hadoop_hdfs_dir }}/nn"
hdfs_datanode_data_dirs: "/data/hdfs/dn"
hdfs_journalnode_data_dirs: "{{ hadoop_hdfs_dir }}/jn"

#jmx-exporter.yml
jmx_exporter:
  startDelaySeconds: 0
  lowercaseOutputName: false
  lowercaseOutputLabelNames: false
  httpServer:
    authentication:
      basic:
        username: "{{ exporter_hdfs_jmxremote_username }}"
        password: "{{ exporter_hdfs_jmxremote_password }}"
    ssl:
      keyStore:
        filename: "{{ hadoop_keystore_location }}"
        password: "{{ hadoop_keystore_password }}"
      certificate:
        alias: "{{ ansible_fqdn }}"

# Custom opts
hadoop_client_custom_opts: ""
hdfs_namenode_custom_opts: ""
hdfs_datanode_custom_opts: ""
hdfs_journalnode_custom_opts: ""
hdfs_httpfs_custom_opts: ""
