# Copyright 2022 TOSIT.IO
# SPDX-License-Identifier: Apache-2.0

---
# Spark version
spark_version: spark3
spark_release: spark-3.2.2-TDP-0.1.0-SNAPSHOT-bin-tdp
spark_dist_file: "{{ spark_release }}.tgz"

# Spark HBase Connector
spark_hbase_connector_enable: false

# Spark users and group
spark_user: spark
hadoop_group: hadoop

# Spark installation directory
spark_root_dir: /opt/tdp
spark_install_dir: "{{ spark_root_dir }}/spark3"

# Spark configuration directories
spark_conf_dir: /etc/spark3
spark_client_conf_dir: "{{ spark_conf_dir }}/conf"
spark_hs_conf_dir: "{{ spark_conf_dir }}/conf.hs"

# Spark pid directories
spark_pid_dir: /var/run/spark3

# Spark logging directory
spark_log_dir: /var/log/spark3

# Properties
hadoop_conf_dir: /etc/hadoop/conf
hadoop_home: "/opt/tdp/hadoop"
hdfs_user: hdfs

# Kerberos
###
# Set to 'no' to skip service principals and keytabs creation.
# This can be useful if TDP operators don't have admin access to the Kerberos server,
# or if the Kerberos server does not support MIT Kerberos tools.
###
krb_create_principals_keytabs: yes

# SSL Keystore and Truststore
spark_keystore_location: /etc/ssl/certs/keystore.jks
spark_keystore_password: Keystore123!
spark_truststore_location: /etc/ssl/certs/truststore.jks
spark_truststore_password: Truststore123!

# Spark History Server kerberos
spark_ui_spnego_principal: "HTTP/{{ ansible_fqdn }}@{{ realm }}"
spark_ui_spnego_keytab: /etc/security/keytabs/spnego.service.keytab

# spark-defaults.conf - common
spark_defaults_common:
  spark.acls.enable: "true"
  spark.ui.view.acls: "spark"

  ###
  # Controlling the Spark's ports for calibration with firewalls
  # If the spark.driver.port fails, it is incremented by 1 and retried.
  # This happens up to spark.port.maxRetries times.
  # spark.blockManager.port must be larger than spark.driver.port + sparkspark.sport.maxRetries
  #
  # Default values are blank strings meaning unrestricted port range.
  # The below spark.driver.port was randomly selected for demonstration purposes only.
  ###
  # spark.driver.port: 40000
  # spark.port.maxRetries: 32
  # spark.blockManager.port: 40033

# spark-default.conf - Spark Client
spark_defaults_client:
  spark.eventLog.dir: hdfs://mycluster/spark3-logs
  spark.eventLog.enabled: "true"
  spark.hadoop.yarn.timeline-service.enabled: "false"
  spark.yarn.historyServer.address: "{{ groups['spark3_hs'][0] | tosit.tdp.access_fqdn(hostvars) }}:18081"
  spark.yarn.appMasterEnv.PYSPARK_PYTHON: python3
  spark.master: yarn
  # Hive configuration
  spark.datasource.hive.warehouse.metastoreUri: |-
    {{ groups['hive_ms'] | 
      map('tosit.tdp.access_fqdn', hostvars) |
      map('regex_replace', '^', 'thrift://')| 
      map('regex_replace', '^(.*)$', '\1:9083') |
      list |
      join(',') }}
  spark.hadoop.hive.zookeeper.quorum: |-
    {{ groups['zk'] | 
      map('tosit.tdp.access_fqdn', hostvars) |
      map('regex_replace', '^(.*)$', '\1:2181') |
      list |
      join(',') }}
  spark.sql.hive.metastore.jars: /opt/tdp/hive/lib/*

# spark-default.conf - Spark History Server
spark_defaults_hs:
  spark.history.kerberos.enabled: "true"
  spark.history.kerberos.keytab: /etc/security/keytabs/spark.service.keytab
  spark.history.kerberos.principal: "spark/{{ ansible_fqdn }}@{{ realm }}"
  spark.history.ui.acls.enable: "true"
  spark.history.ui.admin.acls: "knox"
  spark.history.ui.port: 18082
  spark.ui.filters: org.apache.hadoop.security.authentication.server.AuthenticationFilter
  spark.org.apache.hadoop.security.authentication.server.AuthenticationFilter.params: type=kerberos,kerberos.principal={{ spark_ui_spnego_principal }},kerberos.keytab={{ spark_ui_spnego_keytab }},cookie.domain={{ http_cookie_domain }},signature.secret.file={{ http_secret_location }}
  spark.ssl.historyServer.enabled: "true"
  spark.ssl.historyServer.keyStore: "{{ spark_keystore_location }}"
  spark.ssl.historyServer.keyStorePassword: "{{ spark_keystore_password }}"
  spark.ssl.historyServer.port: 18083
  spark.history.fs.logDirectory: hdfs://mycluster/spark3-logs
  spark.history.provider: org.apache.spark.deploy.history.FsHistoryProvider
  spark.ui.proxyBase: "{% if 'knox' in groups and groups['knox'] %}/gateway/tdpldap/spark3history{% endif %}"

# spark-env.sh - common
spark_env_common:
  PYSPARK_PYTHON: python3
  HADOOP_CONF_DIR: "{{ hadoop_conf_dir }}"
  HADOOP_HOME: "{{ hadoop_home }}"
  HIVE_CONF_DIR: "{{ spark_client_conf_dir }}"
  LD_LIBRARY_PATH: "'{{ hadoop_home }}/lib/native/:$LD_LIBRARY_PATH'"

# spark-env.sh - Spark History Server
spark_env_hs:
  SPARK_LOG_DIR: "{{ spark_log_dir }}"

# spark-env.sh - Spark Client
spark_env_client:

# Service restart policies
spark_hs_restart: "no"

# hive-site.xml - spark client
hive_site_spark:
  hive.metastore.uris: |-
    {{ groups['hive_ms'] | 
      map('tosit.tdp.access_fqdn', hostvars) |
      map('regex_replace', '^', 'thrift://')| 
      map('regex_replace', '^(.*)$', '\1:9083') |
      list |
      join(',') }}
  hive.metastore.uri.selection: RANDOM
  hive.exec.scratchdir: /tmp/spark
  hive.metastore.client.connect.retry.delay: 5
  hive.metastore.client.socket.timeout: 1800
  hive.server2.enable.doAs: "false"
  hive.server2.thrift.port: 10016
  hive.server2.transport.mode: http
  hive.metastore.sasl.enabled: "true"
  hadoop.security.authentication: kerberos
  hive.metastore.use.SSL: "true"
  hive.metastore.truststore.path: "{{ spark_truststore_location }}"
  hive.metastore.truststore.password: "{{ spark_truststore_password }}"
  hive.metastore.kerberos.principal: "hive/_HOST@{{ realm }}"
  hive.metastore.execute.setugi: "true"
  hadoop.rpc.protection: AUTHENTICATION
  hive.execution.engine: spark
