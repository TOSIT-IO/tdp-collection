# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

status = INFO
name = HiveLog4j2
packages = org.apache.hadoop.hive.ql.log

# list of properties
property.hive.log.level = INFO
property.hive.root.logger = {{ hive_root_logger }}
property.hive.log.dir = {{ hive_log_dir }}
property.hive.log.file = hive.log
property.hive.perflogger.log.level = INFO

# list of all appenders
appenders = {%- if enable_ranger_audit_log4j %} RANGERAUDIT, {% endif %}{{ hive_root_logger }}


# console appender
appender.console.type = Console
appender.console.name = console
appender.console.target = SYSTEM_ERR
appender.console.layout.type = PatternLayout
appender.console.layout.pattern = %d{ISO8601} %5p [%t] %c{2}: %m%n

{% if hive_root_logger=="DRFA" %}
# daily rolling file appender
appender.DRFA.type = RollingRandomAccessFile
appender.DRFA.name = DRFA
appender.DRFA.fileName = ${sys:hive.log.dir}/${sys:hive.log.file}
appender.DRFA.filePattern = ${sys:hive.log.dir}/${sys:hive.log.file}.{{ hive_log_drfa_date_pattern }}
appender.DRFA.layout.type = PatternLayout
appender.DRFA.layout.pattern = {{ hive_log_layout_pattern }}
appender.DRFA.policies.type = Policies
appender.DRFA.policies.timebased.type = TimeBasedTriggeringPolicy
appender.DRFA.policies.timebased.interval = 1
appender.DRFA.policies.timebased.modulate = false
appender.DRFA.strategy.type = DefaultRolloverStrategy
appender.DRFA.strategy.max = {{ hive_log_drfa_maxbackupindex }}
{% else %}
# rolling file appender
appender.RFA.type = RollingRandomAccessFile
appender.RFA.name = RFA
appender.RFA.fileName = ${sys:hive.log.dir}/${sys:hive.log.file}
appender.RFA.filePattern = ${sys:hive.log.dir}/${sys:hive.log.file}.%i
appender.RFA.layout.type = PatternLayout
appender.RFA.layout.pattern = {{ hive_log_layout_pattern }}
appender.RFA.policies.type = Policies
appender.RFA.policies.sizebased.type = SizeBasedTriggeringPolicy
appender.RFA.policies.sizebased.size = {{ hive_log_rfa_maxfilesize }}
appender.RFA.strategy.type = DefaultRolloverStrategy
appender.RFA.strategy.max = {{ hive_log_rfa_maxbackupindex }}
{% endif %}

{% if enable_ranger_audit_log4j %}
appender.RANGERAUDIT.type = RollingRandomAccessFile
appender.RANGERAUDIT.name = RANGERAUDIT
appender.RANGERAUDIT.fileName = ${sys:hive.log.dir}/{{ hive_ranger_audit_file }}
appender.RANGERAUDIT.filePattern = ${sys:hive.log.dir}/{{ hive_ranger_audit_file }}.{{ hive_log_drfa_date_pattern }}
appender.RANGERAUDIT.layout.type = PatternLayout
appender.RANGERAUDIT.layout.pattern = {{ tdp_auditlog_layout_pattern }}
appender.RANGERAUDIT.policies.type = Policies
appender.RANGERAUDIT.policies.timebased.type = TimeBasedTriggeringPolicy
appender.RANGERAUDIT.policies.timebased.interval = 1
appender.RANGERAUDIT.policies.timebased.modulate = false
appender.RANGERAUDIT.strategy.type = DefaultRolloverStrategy
appender.RANGERAUDIT.strategy.max = {{ hive_log_drfa_maxbackupindex }}
{% endif %}

# list of all loggers
loggers = NIOServerCnxn, ClientCnxnSocketNIO, DataNucleus, Datastore, JPOX, PerfLogger, AmazonAws, ApacheHttp
{%- if enable_ranger_audit_log4j %}, xaaudit{% endif %}


{% if enable_ranger_audit_log4j %}
logger.xaaudit.name = xaaudit
logger.xaaudit.level = INFO
logger.xaaudit.appenderRef.RANGERAUDIT.ref = RANGERAUDIT
{% endif %}

logger.NIOServerCnxn.name = org.apache.zookeeper.server.NIOServerCnxn
logger.NIOServerCnxn.level = WARN

logger.ClientCnxnSocketNIO.name = org.apache.zookeeper.ClientCnxnSocketNIO
logger.ClientCnxnSocketNIO.level = WARN

logger.DataNucleus.name = DataNucleus
logger.DataNucleus.level = ERROR

logger.Datastore.name = Datastore
logger.Datastore.level = ERROR

logger.JPOX.name = JPOX
logger.JPOX.level = ERROR

logger.AmazonAws.name=com.amazonaws
logger.AmazonAws.level = INFO

logger.ApacheHttp.name=org.apache.http
logger.ApacheHttp.level = INFO

logger.PerfLogger.name = org.apache.hadoop.hive.ql.log.PerfLogger
logger.PerfLogger.level = ${sys:hive.perflogger.log.level}

# root logger
rootLogger.level = ${sys:hive.log.level}
rootLogger.appenderRefs = root
rootLogger.appenderRef.root.ref = ${sys:hive.root.logger}
