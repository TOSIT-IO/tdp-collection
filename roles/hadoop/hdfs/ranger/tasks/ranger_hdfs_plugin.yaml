---
- import_role:
    name: tosit.tdp.hadoop.common

- name: Upload {{ ranger_hdfs_dist_file }}
  copy:
    src: "files/{{ ranger_hdfs_dist_file }}"
    dest: /tmp

- name: Extract {{ ranger_hdfs_dist_file }}
  unarchive:
    src: "/tmp/{{ ranger_hdfs_dist_file }}"
    dest: "{{ hadoop_root_dir }}"
    group: root
    owner: root
    remote_src: yes
    creates: "{{ hadoop_root_dir }}/{{ ranger_hdfs_release }}"

- name: Create symbolic link to Ranger installation
  file:
    src: "{{ hadoop_root_dir }}/{{ ranger_hdfs_release }}"
    dest: "{{ ranger_hdfs_install_dir }}"
    state: link

- name: Template install.properties
  template:
    src: install_hdfs.properties.j2
    dest: "{{ ranger_hdfs_install_dir }}/install.properties"

# Ranger installation scripts finds hadoop at "../hadoop" to add necessary properties to hdfs-site.xml, generate the ranger-*.xml
# It can also be configured with COMPONENT_INSTALL_DIR_NAME but we still have to make /opt/hadoop/etc/hadoop a symbolic link to /etc/hadoop/conf.nn to get the configurations at the right place
# TODO: find a better way to do this

- name: Backup {{ hadoop_install_dir }}/etc/hadoop
  command: mv {{ hadoop_install_dir }}/etc/hadoop {{ hadoop_install_dir }}/etc/hadoop.bk
  args:
    creates: "{{ hadoop_install_dir }}/etc/hadoop.bk"

- name: Create symbolic link from etc/hadoop in {{ hadoop_install_dir }} to actual Namenode config dir
  file:
    src: "{{ hadoop_nn_conf_dir }}"
    dest: "{{ hadoop_install_dir }}/etc/hadoop"
    state: link

# We also need to fix the path of the ranger-policymgr-ssl.xml containing the trustore properties in ranger-hdfs-security.xml
- name: Fix the path of ranger-policymgr-ssl.xml in ranger-hdfs-security-changes.cfg
  lineinfile:
    path: "{{ ranger_hdfs_install_dir }}/install/conf.templates/enable/ranger-hdfs-security-changes.cfg"
    regexp: '^ranger.plugin.hdfs.policy.rest.ssl.config.file\s+([^ ]+) (.*)$'
    line: 'ranger.plugin.hdfs.policy.rest.ssl.config.file    /etc/hadoop/conf.nn/ranger-policymgr-ssl.xml \2'
    backrefs: yes

- name: Run enable-hdfs-plugin.sh
  shell: |
    export JAVA_HOME=/usr/lib/jvm/jre-1.8.0-openjdk
    ./enable-hdfs-plugin.sh
  args:
    chdir: "{{ ranger_hdfs_install_dir }}"

- name: Create HDFS service
  run_once: true
  uri:
    url: "{{ ranger_hdfs_install_properties.POLICY_MGR_URL }}/service/plugins/services"
    method: POST
    body:
      name: "{{ ranger_hdfs_install_properties.REPOSITORY_NAME }}"
      isEnabled: true
      configs:
        username: hdfs
        password: hdfs
        policy.download.auth.users: hdfs
        fs.default.name: hdfs://mycluster
        hadoop.security.authorization: true
        hadoop.security.authentication: kerberos
        dfs.datanode.kerberos.principal: "dn/_HOST@{{ realm }}"
        dfs.namenode.kerberos.principal: "nn/_HOST@{{ realm }}"
        hadoop.rpc.protection: authentication
        #hadoop.security.auth_to_local: ""
      type: hdfs
    body_format: json
    force_basic_auth: yes
    user: admin
    password: "{{ ranger_admin_password }}"
    headers:
      Content-Type: application/json
    status_code: [200, 400]
    validate_certs: no
  register: reg_hdfs
  changed_when: reg_hdfs.status == 200
  failed_when: |
    reg_hdfs is failed or
    reg_hdfs.status == 400 and
    (reg_hdfs.json.msgDesc is not defined or
    'Duplicate service name' not in reg_hdfs.json.msgDesc)

- name: Restart HDFS Namenodes
  service:
    name: hadoop-hdfs-namenode
    state: restarted

